{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16e04f21",
   "metadata": {},
   "source": [
    "### Importing pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4ad197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.1.1-bin-hadoop3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43303ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9d3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Spark Session\n",
    "spark = SparkSession.builder.appName('nlpproject').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca7024",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9572c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Data\n",
    "data = spark.read.csv('SMSSpamCollection',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "030d6d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f23b7e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fddf284",
   "metadata": {},
   "source": [
    "### Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4902e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4d4788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed283ef",
   "metadata": {},
   "source": [
    "### Adding Length Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e48534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6863857",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('length',length(data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdf4be69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|length|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "+-----+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d27a9",
   "metadata": {},
   "source": [
    "#### Comparing whether the length of ham messages are different from spam messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66428015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|      avg(length)|\n",
      "+-----+-----------------+\n",
      "|  ham|71.45431945307645|\n",
      "| spam|138.6706827309237|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('class').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775a247",
   "metadata": {},
   "source": [
    "### NLP Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4acdf3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover,CountVectorizer,IDF,StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4a83516",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='text',outputCol='token_text')\n",
    "stop_remove = StopWordsRemover(inputCol='token_text',outputCol='stop_token')\n",
    "count_vec = CountVectorizer(inputCol='stop_token',outputCol='c_vec')\n",
    "idf = IDF(inputCol='c_vec',outputCol='tf_idf')\n",
    "ham_spam_to_numeric = StringIndexer(inputCol='class',outputCol='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78ea8c",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6c017c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74a55eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols=['tf_idf','length'],outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e9e36",
   "metadata": {},
   "source": [
    "#### Using Pipeline cleaning the text and making it ready for model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3df5f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c33020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing for the above steps\n",
    "data_prep_pipe = Pipeline(stages=[ham_spam_to_numeric,tokenizer,stop_remove,count_vec,idf,clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53540271",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipe.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f00dc5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = cleaner.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6aacc5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'text',\n",
       " 'length',\n",
       " 'label',\n",
       " 'token_text',\n",
       " 'stop_token',\n",
       " 'c_vec',\n",
       " 'tf_idf',\n",
       " 'features']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b84105ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = clean_data.select(['label','features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a74eb255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(13424,[7,11,31,6...|\n",
      "|  0.0|(13424,[0,24,297,...|\n",
      "|  1.0|(13424,[2,13,19,3...|\n",
      "|  0.0|(13424,[0,70,80,1...|\n",
      "|  0.0|(13424,[36,134,31...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2aa273",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f941895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data , test_data = final_data.randomSplit([0.7,0.3],101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3511759",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7b0e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c91dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff8eb2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detector = nb.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe26040",
   "metadata": {},
   "source": [
    "#### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80b58dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = spam_detector.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c716972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(13424,[0,1,4,50,...|[-828.94645027671...|[1.0,1.4407467584...|       0.0|\n",
      "|  0.0|(13424,[0,1,5,15,...|[-999.15650190371...|[1.0,6.5948418058...|       0.0|\n",
      "|  0.0|(13424,[0,1,14,18...|[-1379.6441477676...|[1.0,3.0567822047...|       0.0|\n",
      "|  0.0|(13424,[0,1,14,31...|[-216.91825807345...|[1.0,1.8562786945...|       0.0|\n",
      "|  0.0|(13424,[0,1,17,19...|[-797.51858134302...|[1.0,5.3544747914...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3861d52",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "692a717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0c40635",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46371b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = acc_eval.evaluate(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "114f0990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model\n",
      "0.9297540456835104\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of model')\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
